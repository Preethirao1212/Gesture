{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "#from phue import Bridge\n",
    "#from soco import SoCo\n",
    "#import pygame\n",
    "import time\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "import gtts as gt\n",
    "import os\n",
    "translator = Translator()\n",
    "\n",
    "# General Settings\n",
    "prediction = ''\n",
    "action = ''\n",
    "score = 0\n",
    "img_counter = 500\n",
    "\n",
    "\n",
    "save_images, selected_gesture = True, 'peace'\n",
    "\n",
    "\n",
    "gesture_names = {0: 'Fist',\n",
    "                 1: 'L',\n",
    "                 2: 'Okay',\n",
    "                 3: 'Palm',\n",
    "                 4: 'Peace'}\n",
    "\n",
    "model = load_model('gestmodel.h5')\n",
    "\n",
    "\n",
    "def predict_rgb_image(img):\n",
    "    result = gesture_names[model.predict_classes(img)[0]]\n",
    "    print(result)\n",
    "    return (result)\n",
    "\n",
    "\n",
    "def predict_rgb_image_vgg(image):\n",
    "    image = np.array(image, dtype='float32')\n",
    "    image /= 255\n",
    "    pred_array = model.predict(image)\n",
    "    print(f'pred_array: {pred_array}')\n",
    "    result = gesture_names[np.argmax(pred_array)]\n",
    "    print(f'Result: {result}')\n",
    "    print(max(pred_array[0]))\n",
    "    score = float(\"%0.2f\" % (max(pred_array[0]) * 100))\n",
    "    print(result)\n",
    "    result = translator.translate(result,src='en',dest='ta')\n",
    "    print(result.text)\n",
    "    tts=gt.gTTS(text=result.text,lang='ta')\n",
    "    tts.save(\"tamil.mp3\")\n",
    "    os.system(\"tamil.mp3\")\n",
    "    \n",
    "    return result.text, score\n",
    "\n",
    "\n",
    "\n",
    "cap_region_x_begin = 0.5  # start point/total width\n",
    "cap_region_y_end = 0.8  # start point/total width\n",
    "threshold = 60  # binary threshold\n",
    "blurValue = 41  # GaussianBlur parameter\n",
    "bgSubThreshold = 50\n",
    "learningRate = 0\n",
    "\n",
    "# variableslt\n",
    "isBgCaptured = 0  # bool, whether the background captured\n",
    "triggerSwitch = False  # if true, keyboard simulator works\n",
    "\n",
    "\n",
    "def remove_background(frame):\n",
    "    fgmask = bgModel.apply(frame, learningRate=learningRate)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=fgmask)\n",
    "    return res\n",
    "\n",
    "\n",
    "# Camera\n",
    "camera = cv2.VideoCapture(0)\n",
    "camera.set(10, 200)\n",
    "\n",
    "while camera.isOpened():\n",
    "    ret, frame = camera.read()\n",
    "    frame = cv2.bilateralFilter(frame, 5, 50, 100)  # smoothing filter\n",
    "    frame = cv2.flip(frame, 1)  # flip the frame horizontally\n",
    "    cv2.rectangle(frame, (int(cap_region_x_begin * frame.shape[1]), 0),\n",
    "                  (frame.shape[1], int(cap_region_y_end * frame.shape[0])), (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('original', frame)\n",
    "\n",
    "    # Run once background is captured\n",
    "    if isBgCaptured == 1:\n",
    "        img = remove_background(frame)\n",
    "        img = img[0:int(cap_region_y_end * frame.shape[0]),\n",
    "              int(cap_region_x_begin * frame.shape[1]):frame.shape[1]]  # clip the ROI\n",
    "        \n",
    "\n",
    "        # convert the image into binary image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (blurValue, blurValue), 0)\n",
    "        \n",
    "        ret, thresh = cv2.threshold(blur, threshold, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "       \n",
    "        cv2.putText(thresh, f\"Prediction: {prediction} ({score}%)\", (50, 30), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (255, 255, 255))\n",
    "        \n",
    "        #print('length :' + len(action))\n",
    "        #if(len(action)>0):\n",
    "            \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        cv2.putText(thresh, f\"Action: {action}\", (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (255, 255, 255))  # Draw the text\n",
    "        cv2.imshow('ori', thresh)\n",
    "        \n",
    "\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == 27:  # press ESC to exit all windows at any time\n",
    "        break\n",
    "    elif k == ord('b'):  # press 'b' to capture the background\n",
    "        bgModel = cv2.createBackgroundSubtractorMOG2(0, bgSubThreshold)\n",
    "        #b.set_light(6, on_command)\n",
    "        time.sleep(2)\n",
    "        isBgCaptured = 1\n",
    "        print('Background captured')\n",
    "\n",
    "    elif k == ord('r'):  # press 'r' to reset the background\n",
    "        time.sleep(1)\n",
    "        bgModel = None\n",
    "        triggerSwitch = False\n",
    "        isBgCaptured = 0\n",
    "        print('Reset background')\n",
    "    elif k == 32:\n",
    "        # If space bar pressed\n",
    "        cv2.imshow('original', frame)\n",
    "        # copies 1 channel BW image to all 3 RGB channels\n",
    "        target = np.stack((thresh,) * 3, axis=-1)\n",
    "        target = cv2.resize(target, (224, 224))\n",
    "        target = target.reshape(1, 224, 224, 3)\n",
    "        prediction, score = predict_rgb_image_vgg(target)\n",
    "\n",
    "        if save_images:\n",
    "            cv2.imwrite('test.jpg',thresh)\n",
    "            \n",
    "            img_counter += 1\n",
    "\n",
    "    elif k == ord('t'):\n",
    "\n",
    "        print('Tracker turned on.')\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Select Region of Interest (ROI)\n",
    "        r = cv2.selectROI(frame)\n",
    "\n",
    "        # Crop image\n",
    "        imCrop = frame[int(r[1]):int(r[1] + r[3]), int(r[0]):int(r[0] + r[2])]\n",
    "\n",
    "        # setup initial location of window\n",
    "        r, h, c, w = 250, 400, 400, 400\n",
    "        track_window = (c, r, w, h)\n",
    "        # set up the ROI for tracking\n",
    "        roi = imCrop\n",
    "        hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))\n",
    "        roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "        cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "        # Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "        term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "        while (1):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "                hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "                # apply meanshift to get the new location\n",
    "                ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "                # Draw it on image\n",
    "                pts = cv2.boxPoints(ret)\n",
    "                pts = np.int0(pts)\n",
    "                img2 = cv2.polylines(frame, [pts], True, (0, 255, 0), 2)\n",
    "                cv2.imshow('img2', img2)\n",
    "                k = cv2.waitKey(60) & 0xff\n",
    "                if k == 27:  # if ESC key\n",
    "                    break\n",
    "                else:\n",
    "                    cv2.imwrite(chr(k) + \".jpg\", img2)\n",
    "            else:\n",
    "                break\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
